{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"pnKLzq0ZM144mqz6jpz6cH",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"a51pOqPlQoEej7HCigIJkv",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"U3rKnKtDWMyMlXSfkjv1dx",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import Levenshtein  # библиотека для расчета расстояния Левенштейна\n",
    "\n",
    "# читаем файл и записываем все слова в список\n",
    "with open(\"litw-win.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    words = file.read().split()\n",
    "\n",
    "\n",
    "# заданное предложение\n",
    "sentence = \"Ths book is very goood.\"\n",
    "\n",
    "# разбиваем предложение на слова и исправляем опечатки\n",
    "corrected_sentence = []\n",
    "for word in sentence.split():\n",
    "    if word in words:  # если слово есть в списке words, то оставляем его без изменений\n",
    "        corrected_sentence.append(word)\n",
    "    else:  # иначе ищем ближайшее слово из списка words\n",
    "        closest_word = min(words, key=lambda x: Levenshtein.distance(word, x))\n",
    "        corrected_sentence.append(closest_word)\n",
    "\n",
    "# объединяем слова в исправленное предложение\n",
    "corrected_sentence = \" \".join(corrected_sentence)\n",
    "\n",
    "print(corrected_sentence)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"DfNpvTtBRvlGMBblZmUoSR",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"nZ9yOJUqWSTWKmopcVLzX4",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# разбиваем текст на слова\n",
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''\n",
    "words = nltk.word_tokenize(text, language='russian')\n",
    "\n",
    "# стемминг слов\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "# лемматизация слов\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "print(\"Слова:\", words)\n",
    "print(\"Стемминг:\", stemmed_words)\n",
    "print(\"Лемматизация:\", lemmatized_words)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"jza0W2qKwHjeMlEpnV1rVf",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи CountVectorizer."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"pw51zV2C1sJldQKxDiMMf6",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"DtUtNqG2sC2C3KmLQdwEVP",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# *** Лабораторная работа 9**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"HVgRUFwWnSZASTgiu0qL4t",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**Расстояние редактирования**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"RXMaTn9gyzGOa42aEBC7nm",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Kys108M0Pis9qhx2M1gr3l",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "data = pd.read_csv('preprocessed_descriptions.csv')\n",
    "\n",
    "words = set()\n",
    "for description in data['preprocessed_descriptions']:\n",
    "    if pd.notnull(description): # check for null values\n",
    "        if not isinstance(description, str):\n",
    "            description = str(description) # convert non-string values to strings\n",
    "        words.update(nltk.word_tokenize(description))"
   ],
   "execution_count":6,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "[nltk_data] Downloading package punkt to \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"z3vCLKM94yehIHNCjVSA6C",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "\n",
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"b37Wp6PIDZdSP0yrC7RiRl",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import random\n",
    "import editdistance\n",
    "\n",
    "# загрузка файла preprocessed_descriptions.csv\n",
    "with open('preprocessed_descriptions.csv', 'r') as f:\n",
    "    words = f.read().split()\n",
    "\n",
    "# генерация 5 пар случайных слов из списка\n",
    "pairs = [(random.choice(words), random.choice(words)) for i in range(5)]\n",
    "\n",
    "# рассчет расстояния редактирования для каждой пары слов\n",
    "for w1, w2 in pairs:\n",
    "    distance = editdistance.eval(w1, w2)\n",
    "    print(f'Расстояние между словами \"{w1}\" и \"{w2}\": {distance}')"
   ],
   "execution_count":3,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Расстояние между словами \"as\" и \"rolls\": 4\n",
      "Расстояние между словами \"threads\" и \"my\": 7\n",
      "Расстояние между словами \"this\" и \"this\": 0\n",
      "Расстояние между словами \"carney\" и \"a\": 5\n",
      "Расстояние между словами \"recipes\" и \"comes\": 4\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"9Fup00wuETwpuI7Ezt74Br",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "1.3 Напишите функцию, которая для заданного слова word возвращает k ближайших к нему слов из списка words (близость слов измеряется с помощью расстояния Левенштейна)"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"9IPXUDGws5kBl8nxLt3yxW",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from Levenshtein import distance\n",
    "import heapq\n",
    "\n",
    "\n",
    "def k_nearest_words(word, words, k):\n",
    "    # создаем список пар (расстояние Левенштейна, слово)\n",
    "    distances = [(distance(word, w), w) for w in words]\n",
    "    # используем heapq для нахождения k элементов с наименьшим расстоянием\n",
    "    k_nearest = heapq.nsmallest(k, distances, key=lambda x: x[0])\n",
    "    # возвращаем только слова\n",
    "    return [w for _, w in k_nearest]"
   ],
   "execution_count":4,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"SXpH7W1AqrGskl8YnBGJE9",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "- **Стемминг, лемматизация**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"lhXzQTlmaGx60MfgeYqJoo",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"x3s9yG0aU5MxJS0Grw9G6Z",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"XIkWvqKWAU3nfq537kKvLk",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"VYPiJjSkcPaqYJqrNww46X",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"sSbThKhZkqXrayRYffThYW",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**Векторное представление текста**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"JKIkw7nloOFSsK6ZnxzAjb",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи TfidfVectorizer"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"8Nr6GMgpMyCsr2rx7I9kQ4",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "recipes = pd.read_csv('preprocessed_descriptions.csv', encoding='utf-8')\n",
    "\n",
    "# choose 5 random recipes\n",
    "random_recipes = recipes.sample(n=5)\n",
    "\n",
    "# transform recipe descriptions into vectors using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(random_recipes['preprocessed_descriptions'])\n",
    "\n",
    "# create dataframe with recipe names and their vectors\n",
    "recipe_vectors = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "recipe_vectors.index = random_recipes['name']"
   ],
   "execution_count":8,
   "outputs":[
    {
     "ename":"AttributeError",
     "evalue":"AttributeError: 'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 14 in <module>",
      "AttributeError: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"tJANcEP1i0J9NPW4Rn5Sik",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "recipes = pd.read_csv('preprocessed_descriptions.csv', encoding='utf-8')\n",
    "\n",
    "random_recipes = recipes.sample(n=5)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(random_recipes['preprocessed_descriptions'])\n",
    "\n",
    "recipe_vectors = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "recipe_vectors.index = random_recipes['name']\n",
    "print(recipe_vectors.index)\n"
   ],
   "execution_count":18,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Index(['cornbread  wild mushroom  and rice stuffing',\n",
      "       'mock hummus bi tahini  chickpea   sesame seed  paste',\n",
      "       'pacific northwest stir fried asparagus   sugar snap peas',\n",
      "       'ground beef  wellington  with fennel',\n",
      "       'cheerwine holiday party punch'],\n",
      "      dtype='object', name='name')\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"KT7kq9bfKj6hGiHACP9Fa6",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"q2B7wmckW1nevJ27bScLlV",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# calculate cosine distance between recipe vectors\n",
    "cosine_distances = np.zeros((5, 5))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        cosine_distances[i][j] = cosine(recipe_vectors.iloc[i], recipe_vectors.iloc[j])\n",
    "\n",
    "# create dataframe with recipe names and their cosine distances\n",
    "cosine_distances_df = pd.DataFrame(cosine_distances, columns=random_recipes['name'], index=random_recipes['name'])\n",
    "print(cosine_distances_df)"
   ],
   "execution_count":19,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "name                                                cornbread  wild mushroom  and rice stuffing  \\\n",
      "name                                                                                              \n",
      "cornbread  wild mushroom  and rice stuffing                                                 0.0   \n",
      "mock hummus bi tahini  chickpea   sesame seed  ...                                          1.0   \n",
      "pacific northwest stir fried asparagus   sugar ...                                          1.0   \n",
      "ground beef  wellington  with fennel                                                        1.0   \n",
      "cheerwine holiday party punch                                                               1.0   \n",
      "\n",
      "name                                                mock hummus bi tahini  chickpea   sesame seed  paste  \\\n",
      "name                                                                                                       \n",
      "cornbread  wild mushroom  and rice stuffing                                                  1.000000      \n",
      "mock hummus bi tahini  chickpea   sesame seed  ...                                           0.000000      \n",
      "pacific northwest stir fried asparagus   sugar ...                                           0.891061      \n",
      "ground beef  wellington  with fennel                                                         0.763903      \n",
      "cheerwine holiday party punch                                                                0.785243      \n",
      "\n",
      "name                                                pacific northwest stir fried asparagus   sugar snap peas  \\\n",
      "name                                                                                                           \n",
      "cornbread  wild mushroom  and rice stuffing                                                  1.000000          \n",
      "mock hummus bi tahini  chickpea   sesame seed  ...                                           0.891061          \n",
      "pacific northwest stir fried asparagus   sugar ...                                           0.000000          \n",
      "ground beef  wellington  with fennel                                                         0.911138          \n",
      "cheerwine holiday party punch                                                                0.806609          \n",
      "\n",
      "name                                                ground beef  wellington  with fennel  \\\n",
      "name                                                                                       \n",
      "cornbread  wild mushroom  and rice stuffing                                     1.000000   \n",
      "mock hummus bi tahini  chickpea   sesame seed  ...                              0.763903   \n",
      "pacific northwest stir fried asparagus   sugar ...                              0.911138   \n",
      "ground beef  wellington  with fennel                                            0.000000   \n",
      "cheerwine holiday party punch                                                   0.800931   \n",
      "\n",
      "name                                                cheerwine holiday party punch  \n",
      "name                                                                               \n",
      "cornbread  wild mushroom  and rice stuffing                              1.000000  \n",
      "mock hummus bi tahini  chickpea   sesame seed  ...                       0.785243  \n",
      "pacific northwest stir fried asparagus   sugar ...                       0.806609  \n",
      "ground beef  wellington  with fennel                                     0.800931  \n",
      "cheerwine holiday party punch                                            0.000000  \n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"hpNSi95AOImxnPkuqSPTPT",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"VgJQD1XMUUVyQTIHnZWdSS",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"pymorphy2",
     "version":"0.9.1",
     "source":"PIP"
    },
    {
     "name":"levenshtein",
     "source":"PIP"
    },
    {
     "name":"nltk",
     "version":"3.8.1",
     "source":"PIP"
    },
    {
     "name":"editdistance",
     "version":"0.6.2",
     "source":"PIP"
    }
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}